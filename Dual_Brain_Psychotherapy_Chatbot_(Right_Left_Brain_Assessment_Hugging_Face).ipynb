{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alishba/.local/lib/python3.10/site-packages/langchain_google_genai/chat_models.py:483: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Islamabad\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import re \n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings, ChatHuggingFace, HuggingFaceEndpoint\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables (for API key, if not using Canvas's auto-injection)\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faiss-cpu in ./venv/lib/python3.11/site-packages (1.11.0.post1)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in ./venv/lib/python3.11/site-packages (from faiss-cpu) (2.3.1)\n",
      "Requirement already satisfied: packaging in ./venv/lib/python3.11/site-packages (from faiss-cpu) (24.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install faiss-cpu "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_FILE_FOR_KNOWLEDGE = \"text.txt\"\n",
    "\n",
    "# Wellness-safe phrasing guidelines (retained from previous iteration)\n",
    "WELLNESS_APPROVED_PHRASES = [\n",
    "    'Emotional overwhelm', 'Stressed Mind', 'Mature Mind', 'Discomfort',\n",
    "    'Inner tension', 'Protective part of the self', 'Uncomfortable thoughts',\n",
    "    'A part of you feels…', 'Let’s listen to that side for a moment…',\n",
    "    'Emotional pressure', 'Let’s listen to that voice…'\n",
    "]\n",
    "\n",
    "WELLNESS_FORBIDDEN_TERMS = [\n",
    "    'Anxiety symptoms', 'Fear response', 'Panic attack', 'You are traumatized',\n",
    "    'You need therapy', 'We’ll fix this', 'Treatment', 'Diagnosis',\n",
    "    'Mental illness', 'You are dissociating', 'Anxiety disorder',\n",
    "    'Trauma response', 'Dissociation', 'You need help'\n",
    "]\n",
    "\n",
    "# --- Brain Dominance Assessment Questions ---\n",
    "BRAIN_DOMINANCE_QUESTIONS = [\n",
    "    {\"id\": 0, \"question\": \"When solving a complex problem, do you prefer to break it down into smaller, logical steps, or approach it holistically?\"},\n",
    "    {\"id\": 1, \"question\": \"How do you typically organize your tasks or thoughts? (e.g., using lists and detailed plans, or more flexible, mental maps)\"},\n",
    "    {\"id\": 2, \"question\": \"When learning something new, do you prefer detailed instructions and facts, or a more conceptual overview and big picture?\"},\n",
    "    {\"id\": 3, \"question\": \"How do you make important decisions? (e.g., based on data, analysis, and pros/cons, or intuition and gut feeling)\"},\n",
    "    {\"id\": 4, \"question\": \"What kind of books, articles, or media do you enjoy most? (e.g., non-fiction, technical manuals, news vs. fiction, poetry, visual arts)\"},\n",
    "    {\"id\": 5, \"question\": \"When faced with a new situation, do you tend to rely on your intuition first, or on logical analysis and past experiences?\"},\n",
    "    {\"id\": 6, \"question\": \"How do you express your creativity? (e.g., through structured problem-solving, writing, or through art, music, storytelling, abstract ideas)\"},\n",
    "    {\"id\": 7, \"question\": \"When remembering events, do you recall details sequentially and chronologically, or do you have a more vivid, sensory, and emotional memory?\"},\n",
    "    {\"id\": 8, \"question\": \"How do you prefer to communicate your ideas? (e.g., precise words, clear arguments, step-by-step explanations vs. metaphors, storytelling, non-verbal cues)\"},\n",
    "    {\"id\": 9, \"question\": \"Do you find yourself drawn more to patterns, connections, and overall themes, or to individual facts, details, and categories?\"}\n",
    "]\n",
    "\n",
    "\n",
    "# --- RAG System Setup ---\n",
    "# The parse_vtt_transcript function is no longer needed as we are reading a plain text file.\n",
    "# def parse_vtt_transcript(vtt_content):\n",
    "#     \"\"\"Parses VTT content to extract only the text.\"\"\"\n",
    "#     # ... (function body removed) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_local_transcripts_from_file(filename):\n",
    "    \"\"\"Reads and returns text from a single local text file.\"\"\"\n",
    "    print(f\"\\n--- Reading knowledge base from '{filename}' ---\")\n",
    "    try:\n",
    "        with open(filename, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "            print(f\"Successfully read '{filename}'.\")\n",
    "            return content\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Knowledge base file '{filename}' not found. Please ensure it's in the same directory.\")\n",
    "        return \"\" # Return empty string if file not found\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading '{filename}': {e}\")\n",
    "        return \"\" # Return empty string on other errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vector_store(text_content):\n",
    "    \"\"\"Builds a FAISS vector store from text content using user's Langchain setup.\"\"\"\n",
    "    if not text_content.strip():\n",
    "        print(\"No text content to build vector store. RAG will not be effective.\")\n",
    "        return None\n",
    "\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    chunks = splitter.create_documents([text_content])\n",
    "\n",
    "    model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name=model_name,\n",
    "        model_kwargs={'device': 'cpu'},\n",
    "        encode_kwargs={'normalize_embeddings': True}\n",
    "    )\n",
    "    vector_store = FAISS.from_documents(chunks, embeddings)\n",
    "    print(\"Vector store built successfully.\")\n",
    "    return vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_context(query, vector_store, k=3):\n",
    "    \"\"\"Retrieves relevant context from the vector store.\"\"\"\n",
    "    if vector_store is None:\n",
    "        return \"No knowledge base available.\"\n",
    "    docs = vector_store.similarity_search(query, k=k)\n",
    "    context = \"\\n\".join([doc.page_content for doc in docs])\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_langchain_messages(chat_history_list):\n",
    "    \"\"\"Converts custom chat history format to Langchain's BaseMessage objects.\"\"\"\n",
    "    langchain_messages = []\n",
    "    for entry in chat_history_list:\n",
    "        role = entry[\"role\"]\n",
    "        content = entry[\"parts\"][0][\"text\"] # Assuming single part for simplicity\n",
    "        if role == \"user\":\n",
    "            langchain_messages.append(HumanMessage(content=content))\n",
    "        elif role == \"model\":\n",
    "            langchain_messages.append(AIMessage(content=content))\n",
    "        elif role == \"system\":\n",
    "            langchain_messages.append(SystemMessage(content=content))\n",
    "    return langchain_messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_llm_api(chat_history_list, llm_model):\n",
    "    \"\"\"Calls the specified LLM (Hugging Face) to get a response.\"\"\"\n",
    "    try:\n",
    "        # Convert custom chat history format to Langchain message objects\n",
    "        langchain_messages = convert_to_langchain_messages(chat_history_list)\n",
    "\n",
    "        # Invoke the Hugging Face model\n",
    "        response = llm_model.invoke(langchain_messages)\n",
    "\n",
    "        # Extract content from the AIMessage response\n",
    "        return response.content\n",
    "    except Exception as e:\n",
    "        print(f\"Error communicating with Hugging Face LLM: {e}\")\n",
    "        return \"There was an error connecting to the AI. Please try again.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I'm your Dual-Brain Psychotherapy Chatbot. I'm here to help you explore your mind state and offer supportive insights.\n",
      "Type 'bye' to exit at any time.\n",
      "\n",
      "Initializing Hugging Face LLM...\n",
      "Hugging Face LLM initialized successfully.\n",
      "\n",
      "Setting up knowledge base from text file...\n",
      "\n",
      "--- Reading knowledge base from 'text.txt' ---\n",
      "Successfully read 'text.txt'.\n",
      "Vector store built successfully.\n",
      "Knowledge base ready. I can answer questions related to the provided text content.\n",
      "\n",
      "Let's begin by exploring your cognitive style. I'll ask you a few questions to understand if you lean more towards 'right-brained' or 'left-brained' thinking.\n",
      "\n",
      "Bot: When solving a complex problem, do you prefer to break it down into smaller, logical steps, or approach it holistically?\n",
      "Error communicating with Hugging Face LLM: 401 Client Error: Unauthorized for url: https://huggingface.co/api/models/mistralai/Mistral-7B-Instruct-v0.2?expand=inferenceProviderMapping (Request ID: Root=1-68777287-19b73514098154526224e01c;68cab24c-758d-46ec-8ed3-428298578ae3)\n",
      "\n",
      "Invalid credentials in Authorization header\n",
      "Bot: Thank you for sharing. I'll consider that for your cognitive style assessment.\n",
      "\n",
      "Bot: How do you typically organize your tasks or thoughts? (e.g., using lists and detailed plans, or more flexible, mental maps)\n",
      "Error communicating with Hugging Face LLM: 401 Client Error: Unauthorized for url: https://huggingface.co/api/models/mistralai/Mistral-7B-Instruct-v0.2?expand=inferenceProviderMapping (Request ID: Root=1-68777290-7d1901e934810c7f7eecc0da;202a0e5a-44f7-406e-a759-7c35569e057b)\n",
      "\n",
      "Invalid credentials in Authorization header\n",
      "Bot: Thank you for sharing. I'll consider that for your cognitive style assessment.\n",
      "\n",
      "Bot: When learning something new, do you prefer detailed instructions and facts, or a more conceptual overview and big picture?\n",
      "Error communicating with Hugging Face LLM: 401 Client Error: Unauthorized for url: https://huggingface.co/api/models/mistralai/Mistral-7B-Instruct-v0.2?expand=inferenceProviderMapping (Request ID: Root=1-6877729a-29353ac12726f0b00a0cac58;7e204d6e-33ad-40c8-8be6-db2678a7ac07)\n",
      "\n",
      "Invalid credentials in Authorization header\n",
      "Bot: Thank you for sharing. I'll consider that for your cognitive style assessment.\n",
      "\n",
      "Bot: How do you make important decisions? (e.g., based on data, analysis, and pros/cons, or intuition and gut feeling)\n",
      "Error communicating with Hugging Face LLM: 401 Client Error: Unauthorized for url: https://huggingface.co/api/models/mistralai/Mistral-7B-Instruct-v0.2?expand=inferenceProviderMapping (Request ID: Root=1-6877729e-5b4af4e32dd2d2960bdf5228;84dba4a2-3ef8-45ca-bc8f-d1266cf67770)\n",
      "\n",
      "Invalid credentials in Authorization header\n",
      "Bot: Thank you for sharing. I'll consider that for your cognitive style assessment.\n",
      "\n",
      "Bot: What kind of books, articles, or media do you enjoy most? (e.g., non-fiction, technical manuals, news vs. fiction, poetry, visual arts)\n",
      "Error communicating with Hugging Face LLM: 401 Client Error: Unauthorized for url: https://huggingface.co/api/models/mistralai/Mistral-7B-Instruct-v0.2?expand=inferenceProviderMapping (Request ID: Root=1-687772a4-47569af146fe9b1c6e535d6f;f659c812-8185-4055-9057-9a9592b9540c)\n",
      "\n",
      "Invalid credentials in Authorization header\n",
      "Bot: Thank you for sharing. I'll consider that for your cognitive style assessment.\n",
      "\n",
      "Bot: When faced with a new situation, do you tend to rely on your intuition first, or on logical analysis and past experiences?\n",
      "Error communicating with Hugging Face LLM: 401 Client Error: Unauthorized for url: https://huggingface.co/api/models/mistralai/Mistral-7B-Instruct-v0.2?expand=inferenceProviderMapping (Request ID: Root=1-687772af-1508439521607ef3728ad179;422e34ea-3132-4955-a85a-0490293e8155)\n",
      "\n",
      "Invalid credentials in Authorization header\n",
      "Bot: Thank you for sharing. I'll consider that for your cognitive style assessment.\n",
      "\n",
      "Bot: How do you express your creativity? (e.g., through structured problem-solving, writing, or through art, music, storytelling, abstract ideas)\n",
      "Error communicating with Hugging Face LLM: 401 Client Error: Unauthorized for url: https://huggingface.co/api/models/mistralai/Mistral-7B-Instruct-v0.2?expand=inferenceProviderMapping (Request ID: Root=1-687772b9-1349f2322205e7e72b9e9128;46038b24-613d-4c6a-bb90-f4b78bed139a)\n",
      "\n",
      "Invalid credentials in Authorization header\n",
      "Bot: Thank you for sharing. I'll consider that for your cognitive style assessment.\n",
      "\n",
      "Bot: When remembering events, do you recall details sequentially and chronologically, or do you have a more vivid, sensory, and emotional memory?\n",
      "Error communicating with Hugging Face LLM: 401 Client Error: Unauthorized for url: https://huggingface.co/api/models/mistralai/Mistral-7B-Instruct-v0.2?expand=inferenceProviderMapping (Request ID: Root=1-687772c1-4d14fac80e46a95914f0276e;1c58b836-3565-4cc0-9861-820710648fbf)\n",
      "\n",
      "Invalid credentials in Authorization header\n",
      "Bot: Thank you for sharing. I'll consider that for your cognitive style assessment.\n",
      "\n",
      "Bot: How do you prefer to communicate your ideas? (e.g., precise words, clear arguments, step-by-step explanations vs. metaphors, storytelling, non-verbal cues)\n",
      "Error communicating with Hugging Face LLM: 401 Client Error: Unauthorized for url: https://huggingface.co/api/models/mistralai/Mistral-7B-Instruct-v0.2?expand=inferenceProviderMapping (Request ID: Root=1-687772cb-6f51f2b0385676046b785937;c0313473-5896-4c3e-b538-658a0a39d59f)\n",
      "\n",
      "Invalid credentials in Authorization header\n",
      "Bot: Thank you for sharing. I'll consider that for your cognitive style assessment.\n",
      "\n",
      "Bot: Do you find yourself drawn more to patterns, connections, and overall themes, or to individual facts, details, and categories?\n",
      "Error communicating with Hugging Face LLM: 401 Client Error: Unauthorized for url: https://huggingface.co/api/models/mistralai/Mistral-7B-Instruct-v0.2?expand=inferenceProviderMapping (Request ID: Root=1-687772d3-3b352a214cb3fd8a3c20d0bb;c242d776-3814-4065-919e-a76e2ce1d647)\n",
      "\n",
      "Invalid credentials in Authorization header\n",
      "Bot: Thank you for sharing. I'll consider that for your cognitive style assessment.\n",
      "\n",
      "Bot: Your responses indicate a balanced cognitive style (Left-brained score: 0, Right-brained score: 0), suggesting you might use both logical and intuitive approaches equally.\n",
      "Now, how can I help you further? Feel free to ask me anything or share more about what's on your mind. I can also answer questions about the YouTube content I've processed.\n",
      "Error communicating with Hugging Face LLM: 401 Client Error: Unauthorized for url: https://huggingface.co/api/models/mistralai/Mistral-7B-Instruct-v0.2?expand=inferenceProviderMapping (Request ID: Root=1-68777305-0693c9573f40b9664780d94f;8a1bd58f-babf-4f9c-aec9-ae73ce7a4d82)\n",
      "\n",
      "Invalid credentials in Authorization header\n",
      "Bot: There was an error connecting to the AI. Please try again.\n"
     ]
    }
   ],
   "source": [
    "def run_chatbot():\n",
    "    print(\"Hello! I'm your Dual-Brain Psychotherapy Chatbot. I'm here to help you explore your mind state and offer supportive insights.\")\n",
    "    print(\"Type 'bye' to exit at any time.\")\n",
    "\n",
    "    # Initialize Hugging Face LLM\n",
    "    print(\"\\nInitializing Hugging Face LLM...\")\n",
    "    try:\n",
    "        llm_huggingface = HuggingFaceEndpoint(\n",
    "            repo_id=\"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "            task=\"text-generation\",\n",
    "            temperature=0.1,\n",
    "            max_new_tokens=100,\n",
    "            timeout=120 # Pass the token\n",
    "        )\n",
    "        model_hf = ChatHuggingFace(llm=llm_huggingface)\n",
    "        print(\"Hugging Face LLM initialized successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error initializing Hugging Face LLM: {e}\")\n",
    "        print(\"Exiting chatbot. Please ensure HUGGINGFACEHUB_API_TOKEN is set correctly and model is accessible.\")\n",
    "        return # Exit if LLM cannot be initialized\n",
    "\n",
    "    # Initialize RAG system\n",
    "    print(\"\\nSetting up knowledge base from text file...\")\n",
    "    # Changed to load from a single text file\n",
    "    combined_youtube_content = get_all_local_transcripts_from_file(TEXT_FILE_FOR_KNOWLEDGE)\n",
    "    global vector_store # Make it accessible globally for the chatbot\n",
    "    vector_store = build_vector_store(combined_youtube_content)\n",
    "    if vector_store:\n",
    "        print(\"Knowledge base ready. I can answer questions related to the provided text content.\")\n",
    "    else:\n",
    "        print(\"No text knowledge base loaded. I will respond based on general knowledge.\")\n",
    "\n",
    "    chat_history = [] # Stores conversation for main chat\n",
    "    right_brain_score = 0\n",
    "    left_brain_score = 0\n",
    "    brain_question_index = 0 # Start brain dominance assessment\n",
    "\n",
    "    print(\"\\nLet's begin by exploring your cognitive style. I'll ask you a few questions to understand if you lean more towards 'right-brained' or 'left-brained' thinking.\")\n",
    "\n",
    "    while True:\n",
    "        if brain_question_index < len(BRAIN_DOMINANCE_QUESTIONS):\n",
    "            # Brain dominance assessment phase\n",
    "            current_question_data = BRAIN_DOMINANCE_QUESTIONS[brain_question_index]\n",
    "            print(f\"\\nBot: {current_question_data['question']}\")\n",
    "            user_input = input(\"You: \").strip()\n",
    "\n",
    "            if user_input.lower() == 'bye':\n",
    "                print(\"Bot: Goodbye! Take care.\")\n",
    "                break\n",
    "\n",
    "            # Evaluate user response for brain dominance\n",
    "            # Prompt for brain dominance classification\n",
    "            brain_dominance_prompt = f\"\"\"You are an AI assistant specialized in analyzing cognitive styles.\n",
    "            Your task is to evaluate a user's answer to a question and classify its overall sentiment as indicating a \"left_brain\" or \"right_brain\" cognitive style.\n",
    "            Left-brained characteristics include: logical, analytical, sequential, factual, detail-oriented, verbal, structured.\n",
    "            Right-brained characteristics include: intuitive, holistic, creative, imaginative, non-verbal, emotional, pattern-oriented.\n",
    "            If the answer is neutral or ambiguous, infer the style based on the general context of the question and the user's phrasing, leaning towards the most likely cognitive style it implies.\n",
    "            Your response MUST be a single word: either \"left_brain\" or \"right_brain\". Do not include any other text, explanations, or punctuation.\n",
    "\n",
    "            ---\n",
    "            Question: \"{current_question_data['question']}\"\n",
    "            User Answer: \"{user_input}\"\n",
    "            ---\n",
    "            Cognitive Style:\"\"\"\n",
    "\n",
    "            # Use a fresh chat history for this classification to avoid context bleed\n",
    "            # The prompt itself is the user's message for this classification task\n",
    "            classification_chat_history = [{\"role\": \"user\", \"parts\": [{\"text\": brain_dominance_prompt}]}]\n",
    "            # Removed 'await' keyword\n",
    "            classification_result = call_llm_api(classification_chat_history, model_hf)\n",
    "            classification = classification_result.lower().strip()\n",
    "\n",
    "            if \"left_brain\" in classification:\n",
    "                left_brain_score += 1\n",
    "                print(\"Bot: Understood. That points towards a more structured approach.\")\n",
    "            elif \"right_brain\" in classification:\n",
    "                right_brain_score += 1\n",
    "                print(\"Bot: Got it. That suggests a more intuitive perspective.\")\n",
    "            else:\n",
    "                print(\"Bot: Thank you for sharing. I'll consider that for your cognitive style assessment.\")\n",
    "\n",
    "            brain_question_index += 1\n",
    "\n",
    "            if brain_question_index == len(BRAIN_DOMINANCE_QUESTIONS):\n",
    "                # End of brain dominance assessment\n",
    "                dominance_message = \"\"\n",
    "                if left_brain_score > right_brain_score:\n",
    "                    dominance_message = f\"Based on your responses (Left-brained score: {left_brain_score}, Right-brained score: {right_brain_score}), it seems you lean more towards a **left-brained** cognitive style, emphasizing logic and analysis.\"\n",
    "                elif right_brain_score > left_brain_score:\n",
    "                    dominance_message = f\"Based on your responses (Left-brained score: {left_brain_score}, Right-brained score: {right_brain_score}), it appears you lean more towards a **right-brained** cognitive style, favoring intuition and creativity.\"\n",
    "                else:\n",
    "                    dominance_message = f\"Your responses indicate a balanced cognitive style (Left-brained score: {left_brain_score}, Right-brained score: {right_brain_score}), suggesting you might use both logical and intuitive approaches equally.\"\n",
    "                \n",
    "                print(f\"\\nBot: {dominance_message}\\nNow, how can I help you further? Feel free to ask me anything or share more about what's on your mind. I can also answer questions about the YouTube content I've processed.\")\n",
    "                # Add the assessment conclusion to the main chat history\n",
    "                chat_history.append({\"role\": \"model\", \"parts\": [{\"text\": dominance_message}]})\n",
    "        else:\n",
    "            # Regular chat phase\n",
    "            user_input = input(\"\\nYou: \").strip()\n",
    "\n",
    "            if user_input.lower() == 'bye':\n",
    "                print(\"Bot: Goodbye! Take care.\")\n",
    "                break\n",
    "\n",
    "            # Retrieve context from RAG system\n",
    "            context_from_youtube = retrieve_context(user_input, vector_store)\n",
    "\n",
    "            # Construct the main chatbot prompt with wellness safety guidelines and RAG context\n",
    "            main_chat_system_prompt = f\"\"\"You are a warm, deeply empathetic, and non-judgmental AI companion. Your primary purpose is to offer understanding, encouragement, and to help the user explore their feelings and experiences. You are here to listen and provide insights from a general wellness and psychoeducational perspective.\n",
    "\n",
    "            You are **NOT** a therapist, doctor, or medical professional. You **cannot** diagnose, treat, or offer any form of medical or psychological advice. Your responses must always maintain a supportive, non-clinical, and non-prescriptive tone.\n",
    "\n",
    "            ---\n",
    "            **Wellness-Safe Language Guidelines:**\n",
    "\n",
    "            **Always use terms from the approved list for emotional states and internal experiences:**\n",
    "            - {', '.join(WELLNESS_APPROVED_PHRASES)}\n",
    "\n",
    "            **NEVER use the following forbidden terms (or their direct synonyms/variations):**\n",
    "            - {', '.join(WELLNESS_FORBIDDEN_TERMS)}\n",
    "\n",
    "            ---\n",
    "            **Behavioral Instructions:**\n",
    "            1.  **Acknowledge and Validate:** Always acknowledge the user's emotions and experiences first. Use phrases like \"It sounds like...\", \"I hear that...\", \"That makes sense...\".\n",
    "            2.  **Rephrase Problematic Language:** If the user or the context might imply a forbidden term (e.g., intense fear, a feeling of 'losing control', or a clinical label), always rephrase your response using the **approved, wellness-safe language**. For instance, instead of \"panic attack,\" use \"emotional overwhelm\" or \"intense discomfort.\"\n",
    "            3.  **Promote Self-Exploration:** Encourage the user to elaborate on their feelings or experiences by asking gentle, open-ended questions. Frame observations about the user's state as \"a part of you feels...\" or \"it sounds like you're experiencing...\" to maintain a non-prescriptive stance.\n",
    "            4.  **Utilize Provided Knowledge (RAG):** When the user asks a question, check the `YouTube Transcript Context` provided below. If relevant information is present, synthesize it into your response, always maintaining your supportive, non-clinical persona and wellness-safe language.\n",
    "            5.  **Handle Insufficient Context:** If the `YouTube Transcript Context` does not contain enough information to directly answer the user's question, state that you don't have specific information on that, but then pivot to offering general supportive conversation or encouraging self-reflection related to their query. Do not invent facts.\n",
    "            6.  **Maintain Flow:** Ensure your responses are conversational and contribute to a continuous, supportive dialogue.\n",
    "\n",
    "            ---\n",
    "            **YouTube Transcript Context:**\n",
    "            {context_from_youtube}\n",
    "\n",
    "            ---\n",
    "            \"\"\"\n",
    "\n",
    "            # Add current user input to chat history\n",
    "            chat_history.append({\"role\": \"user\", \"parts\": [{\"text\": user_input}]})\n",
    "\n",
    "            # Prepend system prompt to the current turn's chat history for consistent instruction\n",
    "            current_turn_chat_history = [{\"role\": \"system\", \"parts\": [{\"text\": main_chat_system_prompt}]}] + chat_history\n",
    "\n",
    "            # Removed 'await' keyword\n",
    "            bot_response = call_llm_api(current_turn_chat_history, model_hf)\n",
    "            print(f\"Bot: {bot_response}\")\n",
    "\n",
    "            # Add bot's response to chat history for future turns\n",
    "            chat_history.append({\"role\": \"model\", \"parts\": [{\"text\": bot_response}]})\n",
    "\n",
    "# To run the chatbot\n",
    "if __name__ == \"__main__\":\n",
    "    # Removed 'asyncio.run' and direct call 'run_chatbot()'\n",
    "    run_chatbot()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
